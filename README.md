# Vibeserver

Vibeserver is an ~mostly~ occasionally HTTP compliant webserver that will answer all requests by invoking an LLM which generates the response completely on-the-fly.

Only very basic scaffolding exists to slightly increase the chances of a parseable response – the rest is all left to the LLM's imagination based on request parameters (URL, hostname, headers including the HTTP referer etc)!

## Demo

For a limited time, a demo instance is available on https://vibes.lxgr.net/. It's single-threaded and uses a free hosted LLM backend, so please go easy on it!

It's protected by HTTP basic authentication to provide some protection against crawlers etc., but importantly to avoid confusing. The server will literally generate anything, including liability disclaimers or a lack thereof, a permissive robots.txt file, a legal imprint etc.

**By entering the following credentials and visiting vibes.lxgr.net, or following any of the links below, you do so under the understanding that anything hosted there exists for entertainment purposes only and is automatically generated by a process outside of my control. No contractual or legal agreements expressed there are binding in the real world.**

- Username: `vibesonly`
- Password: `iconsent`

## Setup

- Install [uv](https://github.com/astral-sh/uv) or otherwise install the Python packages [llm](https://llm.datasette.io/en/stable/) and your preferred model adapter. I've successfully tested [llm-mlx](https://github.com/ml-explore/mlx-lm) locally on a Macbook Pro and [llm-openrouter](https://github.com/simonw/llm-openrouter) as an API-based service.
  - For API-based models, you'll need to set up an API key
  - Local models have to be instlled per your plugin's instructions. For `mlx-llm`, running `llm install llm-mlx` and then `llm mlx download-model <modelname>` should do the trick. Non-thinking models work best for acceptable latency.
- Configure your desired port number as `PORT` and model name as `MODEL_NAME`.

## Gallery

### APIs
```
➜  ~ curl http://localhost:3000/api/myip
{
  "ip": "2<redacted>:1"
}%
```

### Blog posts

https://vibes.lxgr.net/blog/2025/05/go-got-it-wrong-why-null-strings-are-essential.html

<img width="1511" alt="image" src="https://github.com/user-attachments/assets/464c8045-abfd-47aa-a4c6-2cc22f4da466" />

### Hacker News

https://vibes.lxgr.net/hackernews/news?p=2

<img width="989" alt="image" src="https://github.com/user-attachments/assets/c834e375-5004-4c4f-8394-a6980f21f978" />

### Guestbook

Leave a message!

https://vibes.lxgr.net/guestbook.php?snow=true&animate=true&color=pink

<img width="1347" alt="image" src="https://github.com/user-attachments/assets/abbe08f5-4784-4ad1-b01e-acaf1dd7896a" />


### 3D graphics

It knows GLSL!

https://vibes.lxgr.net/webgl/shader-demos/simple-rotating-triangle.html

<img width="812" alt="image" src="https://github.com/user-attachments/assets/38aadd20-1f4f-4b99-a573-c6dc1d286df9" />

### Academia

https://vibes.lxgr.net/sigbovik/submissions2025

![image](https://github.com/user-attachments/assets/262a5abf-cf6d-4d1c-bd68-187c4c35b215)


### Anomalies

https://vibes.lxgr.net/scp-wiki/scp-3125

<img width="991" alt="image" src="https://github.com/user-attachments/assets/9ad3528c-1b5d-4365-bf0b-9415f9205533" />


## Feature roadmap

- [ ] Image generation
- [ ] Threads? (but it'll just eat through my token budget faster)
- [ ] Persistence? (probably not)
- [ ] Make it self-hosting (i.e. replace the Python script with an LLM prompt for it, then execute the result)

## Warnings

The output of this web server is inherently unpredictable. It might generate things you do not agree with or want to have hosted on your website.

It will also serve *all* incoming requests, including those for robots.txt, and it might happily invite crawlers in that could then quickly churn through a prepaid LLM API key's budget, or rack up high costs on a billed one.

Access control is accordingly advisable for several resons.

See also [license.txt].
